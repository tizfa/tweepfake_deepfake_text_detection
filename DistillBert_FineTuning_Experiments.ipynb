{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DistillBert_FineTuning_Experiments.ipynb",
   "provenance": [
    {
     "file_id": "1UYNHNkk5Yq_dgIhRiVEFiswGzUJ-pdgs",
     "timestamp": 1583167071972
    }
   ],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyPoqDl5HI4NIPuZYS6XgzmX"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "dd88964febac457cbf62593f5fe10057": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_3f647ef41b27480caf7fe0f3f43f3953",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_98ab3e86efab46279a406d7dc9000068",
       "IPY_MODEL_1f30d507ee364a8281c803a87b3ad9bf"
      ]
     }
    },
    "3f647ef41b27480caf7fe0f3f43f3953": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "98ab3e86efab46279a406d7dc9000068": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_503783a4662c4ffa9c0507e79410a2ad",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 411,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 411,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_93ab395e37f14e0ab02a28db148ee9ed"
     }
    },
    "1f30d507ee364a8281c803a87b3ad9bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_a30f3f3743904efcb8dfe3ef81563a17",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 411/411 [00:00&lt;00:00, 4.85kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_016dcc253ba74bbcbe51796457085d41"
     }
    },
    "503783a4662c4ffa9c0507e79410a2ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "93ab395e37f14e0ab02a28db148ee9ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a30f3f3743904efcb8dfe3ef81563a17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "016dcc253ba74bbcbe51796457085d41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d7644cce1a134f6a8847984b9b9d5f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_b7efa8e004b94c0594138f962956e247",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_d5458a9391824ddaaf3a99c17526d255",
       "IPY_MODEL_ece74ee1d5ba46859096ebbaac73e102"
      ]
     }
    },
    "b7efa8e004b94c0594138f962956e247": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d5458a9391824ddaaf3a99c17526d255": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_c0b0776925a640a5bb0289a8a8d13a56",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 263273408,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 263273408,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_4447151c3ed24d87816a5e8b5a3d20c5"
     }
    },
    "ece74ee1d5ba46859096ebbaac73e102": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_992505e4d28840439188038e04199518",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 263M/263M [00:06&lt;00:00, 40.3MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_7c85efdb2937476886c64ea10a550b0d"
     }
    },
    "c0b0776925a640a5bb0289a8a8d13a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "4447151c3ed24d87816a5e8b5a3d20c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "992505e4d28840439188038e04199518": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "7c85efdb2937476886c64ea10a550b0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3d12d908d62646eb8a95c7493185ab1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_5424ff4aae7140fb9d8e94920c008789",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_15959744c721490b8b3c6b5ac4ca85dc",
       "IPY_MODEL_503e4371d8574c04a30fc3c926bc49e7"
      ]
     }
    },
    "5424ff4aae7140fb9d8e94920c008789": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "15959744c721490b8b3c6b5ac4ca85dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_c3125c187263477ea2267205500c28ee",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 213450,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 213450,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_2895a2e4f94c47148e2acb1dfb2931b7"
     }
    },
    "503e4371d8574c04a30fc3c926bc49e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_646f95f6a516407f966d0533c7f6a751",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 213k/213k [00:00&lt;00:00, 1.34MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_802ba1c9d2534f1083fdad4acedbf2a3"
     }
    },
    "c3125c187263477ea2267205500c28ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "2895a2e4f94c47148e2acb1dfb2931b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "646f95f6a516407f966d0533c7f6a751": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "802ba1c9d2534f1083fdad4acedbf2a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b8270a943b224e28ac30ae67934e0864": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_aef39e4adb1b4160909247517e47e368",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_6ddf919930a948c1af332e98de7bc773",
       "IPY_MODEL_743f855974d74812b777e0de8109e925"
      ]
     }
    },
    "aef39e4adb1b4160909247517e47e368": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6ddf919930a948c1af332e98de7bc773": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_52df5992cfdd478680633b2411cd785a",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 20712,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 20712,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_2adb905b25a148e38adfbd5656c80038"
     }
    },
    "743f855974d74812b777e0de8109e925": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_c540e98dfc644b39ad79b86c9d12c90f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 20712/20712 [26:02&lt;00:00, 13.26it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_644ee57c100d449b8e5e7b834f721bc0"
     }
    },
    "52df5992cfdd478680633b2411cd785a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "2adb905b25a148e38adfbd5656c80038": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c540e98dfc644b39ad79b86c9d12c90f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "644ee57c100d449b8e5e7b834f721bc0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "144d89f479a540388ec3b613289f2c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_8b0dae2f53864178b4663216f0ad4eb5",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_d8709fdbf044498d9ad783680870a398",
       "IPY_MODEL_0e2d968ff9784080904ab38260b7433e"
      ]
     }
    },
    "8b0dae2f53864178b4663216f0ad4eb5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d8709fdbf044498d9ad783680870a398": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_6df1cc29df934e0ab7dbae74567b104e",
      "_dom_classes": [],
      "description": "Epoch 3 of 3: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 3,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 3,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_bab7737bb62b46c38b788ffc232a9b88"
     }
    },
    "0e2d968ff9784080904ab38260b7433e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_e0085c26e3de4ea8833bfc23848ba49b",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 3/3 [25:49&lt;00:00, 516.39s/it]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_18e122de66704638bc502407ace9666c"
     }
    },
    "6df1cc29df934e0ab7dbae74567b104e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "bab7737bb62b46c38b788ffc232a9b88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e0085c26e3de4ea8833bfc23848ba49b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "18e122de66704638bc502407ace9666c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f87d1d640a72450e847de2d7d1280772": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_2d02fe6d50ea45c9bd1a0141fade48c4",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_91e0e27606c6434186dd600cd43b242e",
       "IPY_MODEL_9fb7cd68c3a44a0c93e112b7d2dfd75d"
      ]
     }
    },
    "2d02fe6d50ea45c9bd1a0141fade48c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "91e0e27606c6434186dd600cd43b242e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_cc73569a53764731808640d3768cd2fb",
      "_dom_classes": [],
      "description": "Running Epoch 0: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_85e0250bd41d4cf284ede712e3fc6394"
     }
    },
    "9fb7cd68c3a44a0c93e112b7d2dfd75d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_2649f3c9d8a142469fb809dac4412470",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [25:49&lt;00:00,  1.67it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_7d52261ea65142589299439e501a18f6"
     }
    },
    "cc73569a53764731808640d3768cd2fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "85e0250bd41d4cf284ede712e3fc6394": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2649f3c9d8a142469fb809dac4412470": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "7d52261ea65142589299439e501a18f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "8b3ce87553c149a1b7e718cff934797d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d78ccea45a9c48f3bc509cbdc6e05231",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_4edba2e7e6f149a9ae08dc94a70681bf",
       "IPY_MODEL_4b397c0c00724d598fa8327602d068e7"
      ]
     }
    },
    "d78ccea45a9c48f3bc509cbdc6e05231": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "4edba2e7e6f149a9ae08dc94a70681bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_81ca76752c1c40ecb857b24d73efd41a",
      "_dom_classes": [],
      "description": "Running Epoch 1: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_3beaaec28fc54b7dbf25489954c238e0"
     }
    },
    "4b397c0c00724d598fa8327602d068e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_a56db593085f4794a72c1fa7c89323b7",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [17:16&lt;00:00,  2.50it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_fc6c9265ce0a4d58808b0a7acda3f0f8"
     }
    },
    "81ca76752c1c40ecb857b24d73efd41a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "3beaaec28fc54b7dbf25489954c238e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a56db593085f4794a72c1fa7c89323b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "fc6c9265ce0a4d58808b0a7acda3f0f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "168c4cb79f9c41209caf380044ae0620": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_a6fda627e4df4c7d994bfac8f22bb8e0",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_6a42ca1bf04f4f9685eaa0fcb75efd81",
       "IPY_MODEL_0abd9431ad084ec4859da73c722c7b79"
      ]
     }
    },
    "a6fda627e4df4c7d994bfac8f22bb8e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6a42ca1bf04f4f9685eaa0fcb75efd81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_a953c62b48d44014ab485decad5d2263",
      "_dom_classes": [],
      "description": "Running Epoch 2: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_3bf925c4420d438e96cf5844804a963e"
     }
    },
    "0abd9431ad084ec4859da73c722c7b79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_2ab992d1497045139cf67290a86b3dc0",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [08:48&lt;00:00,  4.90it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_d4ab03d9fe5a421e9acf07da9797ad85"
     }
    },
    "a953c62b48d44014ab485decad5d2263": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "3bf925c4420d438e96cf5844804a963e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2ab992d1497045139cf67290a86b3dc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "d4ab03d9fe5a421e9acf07da9797ad85": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "24d689994f544a0486078887aa02795b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_a4864da120784b7eaf44eb76e6da7299",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_50e5a5cb6aa34d8fa9f7d0aabcf4dcec",
       "IPY_MODEL_f42fbd3baf44423193e8477ac07bc6be"
      ]
     }
    },
    "a4864da120784b7eaf44eb76e6da7299": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "50e5a5cb6aa34d8fa9f7d0aabcf4dcec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_fbce3518cd4341998c9289c7579cdecf",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2558,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2558,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_5f0866403d2a43288b4ea5f2abdf2409"
     }
    },
    "f42fbd3baf44423193e8477ac07bc6be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_74b1bc9e969e4d5cae577ddc927edc9f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2558/2558 [00:20&lt;00:00, 123.36it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_533f94a5df8947e194c0f9b5a49fed54"
     }
    },
    "fbce3518cd4341998c9289c7579cdecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "5f0866403d2a43288b4ea5f2abdf2409": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "74b1bc9e969e4d5cae577ddc927edc9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "533f94a5df8947e194c0f9b5a49fed54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ed490a39cda34b30ab8c4a9a63ef66ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_2bc29204f8f84b5d822679531ecac741",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_e2783afc7096401583276f8cfcd09ba8",
       "IPY_MODEL_8f1df001d6ce4be290ae646dbb96d391"
      ]
     }
    },
    "2bc29204f8f84b5d822679531ecac741": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e2783afc7096401583276f8cfcd09ba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_6d4881a5aa0c44ff934be278022b9a25",
      "_dom_classes": [],
      "description": "Running Evaluation: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 320,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 320,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_37f54899f3a24ed8b199f6094c27452a"
     }
    },
    "8f1df001d6ce4be290ae646dbb96d391": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_b61c49ea32eb4d21a6d783168fadc0e2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 320/320 [00:17&lt;00:00, 18.17it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_266798ed8e4a4f1880e0931143c12c98"
     }
    },
    "6d4881a5aa0c44ff934be278022b9a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "37f54899f3a24ed8b199f6094c27452a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b61c49ea32eb4d21a6d783168fadc0e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "266798ed8e4a4f1880e0931143c12c98": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "85ca0282d588406a854529aa3db74876": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_523743570f3c44b59d93d6ad9a83038c",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_d48d155e7b684b4e91b1deee2814add2",
       "IPY_MODEL_a55f6eddd7c94834865dd0d25af4b769"
      ]
     }
    },
    "523743570f3c44b59d93d6ad9a83038c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d48d155e7b684b4e91b1deee2814add2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_08b14cfd1ba54d77a3d9db11781f2fe1",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2558,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2558,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ad4c8f6d68ba44599f08f338d034f025"
     }
    },
    "a55f6eddd7c94834865dd0d25af4b769": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_b610f9d5e3f34df8b14d0fbb53ccd503",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2558/2558 [00:01&lt;00:00, 1766.81it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_63d29b172feb4cb899148e109bf3ab0b"
     }
    },
    "08b14cfd1ba54d77a3d9db11781f2fe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ad4c8f6d68ba44599f08f338d034f025": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b610f9d5e3f34df8b14d0fbb53ccd503": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "63d29b172feb4cb899148e109bf3ab0b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b168db505f5d435aad477d44408eb7cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_2026c9667b4b480e912ee75b86d33150",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_86e1f4d8f4994ae590191113b6ffcc98",
       "IPY_MODEL_dbc466493677488badac79ed4e0f037c"
      ]
     }
    },
    "2026c9667b4b480e912ee75b86d33150": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "86e1f4d8f4994ae590191113b6ffcc98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_eee6c7456a8f43528764de2a88eb68be",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 320,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 320,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_6f1e05208aee49abb5ec88385eff8eda"
     }
    },
    "dbc466493677488badac79ed4e0f037c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_27e51556c326477f8868b912bea14170",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 320/320 [00:17&lt;00:00, 18.10it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_2900fa22d63447e183dd692dd1987b96"
     }
    },
    "eee6c7456a8f43528764de2a88eb68be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "6f1e05208aee49abb5ec88385eff8eda": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "27e51556c326477f8868b912bea14170": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "2900fa22d63447e183dd692dd1987b96": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "YDHCjaH5QrDk",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426340595,
     "user_tz": -120,
     "elapsed": 23958,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "6720e022-65e7-4195-bcd0-d65ddf3fdd70"
   },
   "source": [
    "#%tensorflow_version 2.x\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_t6gg1ZLRYxS",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426340596,
     "user_tz": -120,
     "elapsed": 23951,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "import sys\n",
    "projectDir = \"/content/drive/My Drive/code/git/tweepfake_deepfake_text_detection\"\n",
    "sys.path.insert(0, projectDir)\n",
    "\n",
    "random_state = 523 # Fixed seed for replicability of randomic operations.\n",
    "resultsDir = projectDir+\"/data/results\""
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DuMYSMSjTjdr",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426340596,
     "user_tz": -120,
     "elapsed": 23946,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "ddf1d356-be11-49cf-cbf4-a6ebe69f3ad2"
   },
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "export CUDA_HOME=/usr/local/cuda-10.1\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Writing setup.sh\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sW5qeRXxVQMB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426903812,
     "user_tz": -120,
     "elapsed": 587156,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "e5f56151-9432-4073-feb6-7d99f2168cd4"
   },
   "source": [
    "!sh setup.sh"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 14, done.\u001B[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001B[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001B[K\n",
      "remote: Total 7367 (delta 3), reused 0 (delta 0), pack-reused 7353\u001B[K\n",
      "Receiving objects: 100% (7367/7367), 13.88 MiB | 20.63 MiB/s, done.\n",
      "Resolving deltas: 100% (4976/4976), done.\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-2itr9ljb\n",
      "Created temporary directory: /tmp/pip-req-tracker-nseufc1z\n",
      "Created requirements tracker '/tmp/pip-req-tracker-nseufc1z'\n",
      "Created temporary directory: /tmp/pip-install-6d62p93z\n",
      "Processing ./apex\n",
      "  Created temporary directory: /tmp/pip-req-build-uvtm_dg_\n",
      "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-nseufc1z'\n",
      "    Running setup.py (path:/tmp/pip-req-build-uvtm_dg_/setup.py) egg_info for package from file:///content/apex\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.1+cu101\n",
      "\n",
      "\n",
      "    running egg_info\n",
      "    creating /tmp/pip-req-build-uvtm_dg_/pip-egg-info/apex.egg-info\n",
      "    writing /tmp/pip-req-build-uvtm_dg_/pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-req-build-uvtm_dg_/pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-req-build-uvtm_dg_/pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-req-build-uvtm_dg_/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file '/tmp/pip-req-build-uvtm_dg_/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-uvtm_dg_/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Source in /tmp/pip-req-build-uvtm_dg_ has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
      "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-nseufc1z'\n",
      "Skipping wheel build for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-cjd5asos\n",
      "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-uvtm_dg_/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-uvtm_dg_/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-cjd5asos/install-record.txt --single-version-externally-managed --compile\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.1+cu101\n",
      "\n",
      "\n",
      "    /tmp/pip-req-build-uvtm_dg_/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "    Cuda compilation tools, release 10.1, V10.1.243\n",
      "    from /usr/local/cuda-10.1/bin\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
      "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
      "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    running build_ext\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "      warnings.warn(msg.format('we could not find ninja.'))\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         return tensors[0].type();\n",
      "                                ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/flatten_unflatten.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'syncbn' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_layer_norm_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(gamma);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(beta);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(dout);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(mean);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(invvar);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(dout);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(mean);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(invvar);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(gamma);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(beta);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'mlp_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
      "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < num_layers; i++) {\n",
      "                       ~~^~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
      "                                                                                 ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                        ^\n",
      "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "                                                          ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "         const auto& the_type = TYPE;                                             \\\n",
      "                                ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                            ^\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
      "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < num_layers; i++) {\n",
      "                       ~~^~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < inputs.size(); i++) {\n",
      "                       ~~^~~~~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
      "                                                                       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "                                                          ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "         const auto& the_type = TYPE;                                             \\\n",
      "                                ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                            ^\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    running install_lib\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
      "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "    running install_egg_info\n",
      "    running egg_info\n",
      "    creating apex.egg-info\n",
      "    writing apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to apex.egg-info/top_level.txt\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
      "    running install_scripts\n",
      "    writing list of installed files to '/tmp/pip-record-cjd5asos/install-record.txt'\n",
      "    Running setup.py install for apex ... \u001B[?25l\u001B[?25hdone\n",
      "  Removing source in /tmp/pip-req-build-uvtm_dg_\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "Removed build tracker '/tmp/pip-req-tracker-nseufc1z'\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XqnRBYPkcx_g",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426903817,
     "user_tz": -120,
     "elapsed": 587155,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    ""
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V3qW3001RonB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426919883,
     "user_tz": -120,
     "elapsed": 603216,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "c2738308-3e99-4294-ac8b-0843b0202971"
   },
   "source": [
    "!pip install pandas transformers simpletransformers==0.41 amp"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
      "Collecting transformers\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "\u001B[K     |████████████████████████████████| 778kB 3.5MB/s \n",
      "\u001B[?25hCollecting simpletransformers==0.41\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/99/0d/4e3d32c543e340a52dfbf908b1cc2dea16b605ba0c67a6fb39654c73d555/simpletransformers-0.41.0-py3-none-any.whl (191kB)\n",
      "\u001B[K     |████████████████████████████████| 194kB 16.8MB/s \n",
      "\u001B[?25hCollecting amp\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/cb/9bab4fdd2d8f1d2aacc7cf2d20ad84fa4196d276b3a494960787453b31e9/AMP-1.1.4.tar.gz\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1MB 22.7MB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Collecting sacremoses\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001B[K     |████████████████████████████████| 890kB 16.3MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001B[K     |████████████████████████████████| 3.0MB 32.6MB/s \n",
      "\u001B[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting tensorboardx\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
      "\u001B[K     |████████████████████████████████| 317kB 38.7MB/s \n",
      "\u001B[?25hCollecting seqeval\n",
      "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from simpletransformers==0.41) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simpletransformers==0.41) (1.4.1)\n",
      "Requirement already satisfied: Django>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from amp) (3.0.8)\n",
      "Collecting caldav==0.1.4\n",
      "  Downloading https://files.pythonhosted.org/packages/53/c6/181e4dbe8ee69e1161687991262d79b070282c93833298be2cc8ca1f6ade/caldav-0.1.4.tar.gz\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers==0.41) (3.12.2)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->simpletransformers==0.41) (2.3.1)\n",
      "Requirement already satisfied: asgiref~=3.2 in /usr/local/lib/python3.6/dist-packages (from Django>=1.1.1->amp) (3.2.10)\n",
      "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from Django>=1.1.1->amp) (0.3.1)\n",
      "Collecting vobject\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/da/ce/27c48c0e39cc69ffe7f6e3751734f6073539bf18a0cfe564e973a3709a52/vobject-0.9.6.1.tar.gz (58kB)\n",
      "\u001B[K     |████████████████████████████████| 61kB 6.5MB/s \n",
      "\u001B[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from caldav==0.1.4->amp) (4.2.6)\n",
      "Collecting nose\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "\u001B[K     |████████████████████████████████| 163kB 36.7MB/s \n",
      "\u001B[?25hRequirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from caldav==0.1.4->amp) (3.7.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers==0.41) (49.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (1.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (3.13)\n",
      "Building wheels for collected packages: amp, sacremoses, seqeval, caldav, vobject\n",
      "  Building wheel for amp (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for amp: filename=AMP-1.1.4-cp36-none-any.whl size=9417 sha256=a0393f6bf30c8c2e5a159cd2a94664cd3e83cfb0af30ff61e2d093e02e85fe9f\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/9c/a0/acaeece5c47a0249f6152849c2e694fee9afbb43a8864b9128\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2c6fb43c19277da3fd731225fc10d53c537d4d856baf9c6a1c651ff51b1c9a4b\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "  Building wheel for seqeval (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=6cd69aca4751c866b229a5558068226f1819f9256a844a925c6c24e46a6ada5f\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
      "  Building wheel for caldav (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for caldav: filename=caldav-0.1.4-cp36-none-any.whl size=12305 sha256=997ed7daac2adffbc909e5fe418c5e74defd65e3ceb69098442458d6d4c3e234\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/65/04/138802f7957e4ee778dde8fb03eb406fcd2f15e12baee1ef66\n",
      "  Building wheel for vobject (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for vobject: filename=vobject-0.9.6.1-cp36-none-any.whl size=47664 sha256=e29a2c57544a33543a25285b898b2911de658462067eec397e185325c1545068\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/4b/53/aaf3243d7bd9bcf636b1a17dee2f075cecc8581a387548b5a8\n",
      "Successfully built amp sacremoses seqeval caldav vobject\n",
      "\u001B[31mERROR: simpletransformers 0.41.0 has requirement tokenizers<=0.7, but you'll have tokenizers 0.8.1rc1 which is incompatible.\u001B[0m\n",
      "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers, tensorboardx, seqeval, simpletransformers, vobject, nose, caldav, amp\n",
      "Successfully installed amp-1.1.4 caldav-0.1.4 nose-1.3.7 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-0.0.12 simpletransformers-0.41.0 tensorboardx-2.1 tokenizers-0.8.1rc1 transformers-3.0.2 vobject-0.9.6.1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lLsNhiofRy5r",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426923567,
     "user_tz": -120,
     "elapsed": 606894,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "from DataHandler import DataHandler\n",
    "\n",
    "csvTrainDataset = projectDir+\"/data/splits/train.csv\"\n",
    "csvValDataset = projectDir+\"/data/splits/validation.csv\"\n",
    "csvTestDataset = projectDir+\"/data/splits/test.csv\"\n",
    "\n",
    "bertDir = projectDir+\"/data/encoded/bert\"\n",
    "dh = DataHandler()\n",
    "dfTrain = dh.readCSVData(csvTrainDataset)\n",
    "dfVal = dh.readCSVData(csvValDataset)\n",
    "dfTest = dh.readCSVData(csvTestDataset)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mBCDg773SZKW",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426923568,
     "user_tz": -120,
     "elapsed": 606889,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "70dc3b57-c8fe-4a3a-b9fc-a47a433683ad"
   },
   "source": [
    "dfTrain"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_prog</th>\n",
       "      <th>user_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>symbols</th>\n",
       "      <th>urls_url</th>\n",
       "      <th>urls_t.co</th>\n",
       "      <th>urls_expanded_url</th>\n",
       "      <th>media_url</th>\n",
       "      <th>media_t.co</th>\n",
       "      <th>media_expanded_url</th>\n",
       "      <th>media_type</th>\n",
       "      <th>ext_media_url</th>\n",
       "      <th>ext_media_t.co</th>\n",
       "      <th>ext_media_expanded_url</th>\n",
       "      <th>ext_media_type</th>\n",
       "      <th>mentions_user_id</th>\n",
       "      <th>mentions_screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_text</th>\n",
       "      <th>quoted_created_at</th>\n",
       "      <th>quoted_source</th>\n",
       "      <th>quoted_favorite_count</th>\n",
       "      <th>quoted_retweet_count</th>\n",
       "      <th>quoted_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>place_url</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_coords</th>\n",
       "      <th>coords_coords</th>\n",
       "      <th>bbox_coords</th>\n",
       "      <th>status_url</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>protected</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>profile_url</th>\n",
       "      <th>profile_expanded_url</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>profile_banner_url</th>\n",
       "      <th>profile_background_url</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>created</th>\n",
       "      <th>data.tweet</th>\n",
       "      <th>ora.tweet</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>mention_TF</th>\n",
       "      <th>hashtag_TF</th>\n",
       "      <th>url_TF</th>\n",
       "      <th>n.words</th>\n",
       "      <th>punct</th>\n",
       "      <th>account.type</th>\n",
       "      <th>finetuning_source</th>\n",
       "      <th>class_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14692</td>\n",
       "      <td>x1110407881030017024</td>\n",
       "      <td>x1208265880146046976</td>\n",
       "      <td>2019-12-21 06:00:08</td>\n",
       "      <td>imranyebot</td>\n",
       "      <td>YEA now that note GOOD</td>\n",
       "      <td>imranye-twitter-bot</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/imranyebot/status/12082658...</td>\n",
       "      <td>imranyebot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@imranye in robot form. tweets every hour gene...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7467</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-26 05:07:23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1110408254...</td>\n",
       "      <td>2019-12-21 06:00:08</td>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>06:00:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>imranye</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22336</td>\n",
       "      <td>x3171109449</td>\n",
       "      <td>x1091463908118941696</td>\n",
       "      <td>2019-02-01 22:30:48</td>\n",
       "      <td>zawvrk</td>\n",
       "      <td>Listen to This Charming Man by The Smiths  htt...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>soundcloud.com/thesmiths/this…</td>\n",
       "      <td>https://t.co/r12OIXkfUO</td>\n",
       "      <td>https://soundcloud.com/thesmiths/this-charming...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/zawvrk/status/109146390811...</td>\n",
       "      <td>zawar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gold experience</td>\n",
       "      <td>https://t.co/J60plTSsKt</td>\n",
       "      <td>False</td>\n",
       "      <td>558</td>\n",
       "      <td>274</td>\n",
       "      <td>8</td>\n",
       "      <td>12216</td>\n",
       "      <td>23633</td>\n",
       "      <td>2015-04-15 19:50:16</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/J60plTSsKt</td>\n",
       "      <td>https://www.instagram.com/zawvr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/31711094...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1229957200...</td>\n",
       "      <td>2019-02-01 22:30:48</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>22:30:48</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>human</td>\n",
       "      <td>original</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24087</td>\n",
       "      <td>x1110686081341632512</td>\n",
       "      <td>x1199055191028293633</td>\n",
       "      <td>2019-11-25 20:00:09</td>\n",
       "      <td>zawarbot</td>\n",
       "      <td>wish i can i would be seeing other hoes on the...</td>\n",
       "      <td>zawar-twitter-bot</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/zawarbot/status/1199055191...</td>\n",
       "      <td>zawarbot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I’m an AI Bot that tries to tweet like @zawvrk...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4054</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-03-26 23:32:52</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1185589257...</td>\n",
       "      <td>2019-11-25 20:00:09</td>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>20:00:09</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>zawvrk</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7584</td>\n",
       "      <td>x1110307772783124480</td>\n",
       "      <td>x1214698264701722626</td>\n",
       "      <td>2020-01-08 00:00:08</td>\n",
       "      <td>ahadsheriffbot</td>\n",
       "      <td>The decade in the significantly easier schedul...</td>\n",
       "      <td>ahadsheriff-bot</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/ahadsheriffbot/status/1214...</td>\n",
       "      <td>Robot Ahad Sheriff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@ahadsheriff in robot form. tweets every hour ...</td>\n",
       "      <td>https://t.co/2G243YsNOt</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7946</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-25 22:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/2G243YsNOt</td>\n",
       "      <td>https://ahadsheriff.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1110311752...</td>\n",
       "      <td>2020-01-08 00:00:08</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>00:00:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>bot</td>\n",
       "      <td>ahadsheriff</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19654</td>\n",
       "      <td>x979586167405363200</td>\n",
       "      <td>x1209229478934695937</td>\n",
       "      <td>2019-12-23 21:49:08</td>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Theim class=\\\"alignnone size-full wp-image-60...</td>\n",
       "      <td>kevinhooke-ml-bot</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kevinhooke.com/wp-content/upl…</td>\n",
       "      <td>https://t.co/LiAsQsbs99</td>\n",
       "      <td>https://www.kevinhooke.com/wp-content/uploads/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/kevinhookebot/status/12092...</td>\n",
       "      <td>Kevin Hooke Bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm an AWS Lambda generating content from a Re...</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6608</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 05:08:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>https://www.kevinhooke.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/sticky/default_profile_im...</td>\n",
       "      <td>2019-12-23 21:49:08</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>21:49:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>bot</td>\n",
       "      <td>kevinhooke</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20707</th>\n",
       "      <td>1538</td>\n",
       "      <td>x1197916267975335939</td>\n",
       "      <td>x1204245032917700608</td>\n",
       "      <td>2019-12-10 03:42:44</td>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Met on the Abversion of our science for the co...</td>\n",
       "      <td>AI_Narendra_Modi</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>life.Om</td>\n",
       "      <td>https://t.co/kl5Dfl0y18</td>\n",
       "      <td>http://life.Om</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/AINarendraModi/status/1204...</td>\n",
       "      <td>AI Narendra Modi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Narendra Modi but with AI\\r\\nBot commands - ht...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-22 16:34:45</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/11979162...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1197916520...</td>\n",
       "      <td>2019-12-10 03:42:44</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>03:42:44</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>bot</td>\n",
       "      <td>narendramodi</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>1885</td>\n",
       "      <td>x1197916267975335939</td>\n",
       "      <td>x1207011474243309570</td>\n",
       "      <td>2019-12-17 18:55:35</td>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Land for their during the opportunity to the p...</td>\n",
       "      <td>AI_Narendra_Modi</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/AINarendraModi/status/1207...</td>\n",
       "      <td>AI Narendra Modi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Narendra Modi but with AI\\r\\nBot commands - ht...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-22 16:34:45</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/11979162...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1197916520...</td>\n",
       "      <td>2019-12-17 18:55:35</td>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>18:55:35</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>bot</td>\n",
       "      <td>narendramodi</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20709</th>\n",
       "      <td>3930</td>\n",
       "      <td>x705113652471439361</td>\n",
       "      <td>x715558455285837824</td>\n",
       "      <td>2016-03-31 15:16:44</td>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>@TayandYou doesn't have a clue. You're right. ...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>133</td>\n",
       "      <td>x714838749860012032</td>\n",
       "      <td>x78324623</td>\n",
       "      <td>eldiariodedross</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x4531940473 x78324623</td>\n",
       "      <td>TayandYou eldiariodedross</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/DeepDrumpf/status/71555845...</td>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm a Neural Network trained on Trump's transc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>25401</td>\n",
       "      <td>7</td>\n",
       "      <td>296</td>\n",
       "      <td>286</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-03-02 19:32:49</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/70511365...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/7054647353...</td>\n",
       "      <td>2016-03-31 15:16:44</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>15:16:44</td>\n",
       "      <td>reply</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>bot</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>729</td>\n",
       "      <td>x262794965</td>\n",
       "      <td>x812868913239199745</td>\n",
       "      <td>2016-12-25 03:53:45</td>\n",
       "      <td>jaden</td>\n",
       "      <td>Me And My Bestie https://t.co/vPq2iDkWZm</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7265</td>\n",
       "      <td>1071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/media/C0fj97lUQAAT-dC.jpg</td>\n",
       "      <td>https://t.co/vPq2iDkWZm</td>\n",
       "      <td>https://twitter.com/officialjaden/status/81286...</td>\n",
       "      <td>photo</td>\n",
       "      <td>http://pbs.twimg.com/media/C0fj97lUQAAT-dC.jpg</td>\n",
       "      <td>https://t.co/vPq2iDkWZm</td>\n",
       "      <td>https://twitter.com/officialjaden/status/81286...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/jaden/status/8128689132391...</td>\n",
       "      <td>Jaden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;U+0001F308&gt; Boy</td>\n",
       "      <td>https://t.co/2dZJOThjAQ</td>\n",
       "      <td>False</td>\n",
       "      <td>8142789</td>\n",
       "      <td>188</td>\n",
       "      <td>14893</td>\n",
       "      <td>5669</td>\n",
       "      <td>1844</td>\n",
       "      <td>2011-03-08 19:41:06</td>\n",
       "      <td>True</td>\n",
       "      <td>https://t.co/2dZJOThjAQ</td>\n",
       "      <td>https://jaden.link/erys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/26279496...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1146090110...</td>\n",
       "      <td>2016-12-25 03:53:45</td>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>03:53:45</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "      <td>original</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>19366</td>\n",
       "      <td>x979586167405363200</td>\n",
       "      <td>x1194703766303338496</td>\n",
       "      <td>2019-11-13 19:49:09</td>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Thead has a generate existing the Sparching f...</td>\n",
       "      <td>kevinhooke-ml-bot</td>\n",
       "      <td>205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/kevinhookebot/status/11947...</td>\n",
       "      <td>Kevin Hooke Bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm an AWS Lambda generating content from a Re...</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6608</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 05:08:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>https://www.kevinhooke.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/sticky/default_profile_im...</td>\n",
       "      <td>2019-11-13 19:49:09</td>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>19:49:09</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>bot</td>\n",
       "      <td>kevinhooke</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20712 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      N_prog               user_id  ... finetuning_source class_type\n",
       "0      14692  x1110407881030017024  ...           imranye     others\n",
       "1      22336           x3171109449  ...          original      human\n",
       "2      24087  x1110686081341632512  ...            zawvrk     others\n",
       "3       7584  x1110307772783124480  ...       ahadsheriff     others\n",
       "4      19654   x979586167405363200  ...        kevinhooke        rnn\n",
       "...      ...                   ...  ...               ...        ...\n",
       "20707   1538  x1197916267975335939  ...      narendramodi        rnn\n",
       "20708   1885  x1197916267975335939  ...      narendramodi        rnn\n",
       "20709   3930   x705113652471439361  ...   realDonaldTrump        rnn\n",
       "20710    729            x262794965  ...          original      human\n",
       "20711  19366   x979586167405363200  ...        kevinhooke        rnn\n",
       "\n",
       "[20712 rows x 103 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c0oedq8-W7u2",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426923569,
     "user_tz": -120,
     "elapsed": 606885,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "# Select interesting columns for this study.\n",
    "dfTrainDataset = dfTrain[[\"screen_name\", \"text\", \"account.type\"]]\n",
    "dfValDataset = dfVal[[\"screen_name\", \"text\", \"account.type\"]]\n",
    "dfTestDataset = dfTest[[\"screen_name\", \"text\", \"account.type\"]]"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qTeVpVc6I9Lb",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426923569,
     "user_tz": -120,
     "elapsed": 606880,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "7cf1088f-0423-45ba-f963-c494eda01b31"
   },
   "source": [
    "dfTrainDataset"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>account.type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imranyebot</td>\n",
       "      <td>YEA now that note GOOD</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zawvrk</td>\n",
       "      <td>Listen to This Charming Man by The Smiths  htt...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zawarbot</td>\n",
       "      <td>wish i can i would be seeing other hoes on the...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ahadsheriffbot</td>\n",
       "      <td>The decade in the significantly easier schedul...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Theim class=\\\"alignnone size-full wp-image-60...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20707</th>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Met on the Abversion of our science for the co...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Land for their during the opportunity to the p...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20709</th>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>@TayandYou doesn't have a clue. You're right. ...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>jaden</td>\n",
       "      <td>Me And My Bestie https://t.co/vPq2iDkWZm</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Thead has a generate existing the Sparching f...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20712 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_name  ... account.type\n",
       "0          imranyebot  ...          bot\n",
       "1              zawvrk  ...        human\n",
       "2            zawarbot  ...          bot\n",
       "3      ahadsheriffbot  ...          bot\n",
       "4       kevinhookebot  ...          bot\n",
       "...               ...  ...          ...\n",
       "20707  AINarendraModi  ...          bot\n",
       "20708  AINarendraModi  ...          bot\n",
       "20709      DeepDrumpf  ...          bot\n",
       "20710           jaden  ...        human\n",
       "20711   kevinhookebot  ...          bot\n",
       "\n",
       "[20712 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yvFnZqKMIY4F",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426923570,
     "user_tz": -120,
     "elapsed": 606874,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "X_train_all = dfTrainDataset.drop(columns=['screen_name'])\n",
    "X_train_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "X_val_all = dfValDataset.drop(columns=['screen_name'])\n",
    "X_val_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "X_test_all = dfTestDataset.drop(columns=['screen_name'])\n",
    "X_test_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "dictLabels = {\"human\":0, \"bot\":1}\n",
    "dictLabelsReverse = {0:\"human\", 1: \"bot\"}\n",
    "\n",
    "X_train_all[\"label\"] = X_train_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "X_val_all[\"label\"] = X_val_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "X_test_all[\"label\"] = X_test_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "y_train = X_train_all[\"label\"]\n",
    "y_val = X_val_all[\"label\"]\n",
    "y_test = X_test_all[\"label\"]"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xDAhMIgmpxTs",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595426923571,
     "user_tz": -120,
     "elapsed": 606870,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "train_labels = y_train.tolist()\n",
    "val_labels = y_val.tolist()\n",
    "test_labels = y_test.tolist()"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QtE2szKKPis5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616,
     "referenced_widgets": [
      "dd88964febac457cbf62593f5fe10057",
      "3f647ef41b27480caf7fe0f3f43f3953",
      "98ab3e86efab46279a406d7dc9000068",
      "1f30d507ee364a8281c803a87b3ad9bf",
      "503783a4662c4ffa9c0507e79410a2ad",
      "93ab395e37f14e0ab02a28db148ee9ed",
      "a30f3f3743904efcb8dfe3ef81563a17",
      "016dcc253ba74bbcbe51796457085d41",
      "d7644cce1a134f6a8847984b9b9d5f66",
      "b7efa8e004b94c0594138f962956e247",
      "d5458a9391824ddaaf3a99c17526d255",
      "ece74ee1d5ba46859096ebbaac73e102",
      "c0b0776925a640a5bb0289a8a8d13a56",
      "4447151c3ed24d87816a5e8b5a3d20c5",
      "992505e4d28840439188038e04199518",
      "7c85efdb2937476886c64ea10a550b0d",
      "3d12d908d62646eb8a95c7493185ab1c",
      "5424ff4aae7140fb9d8e94920c008789",
      "15959744c721490b8b3c6b5ac4ca85dc",
      "503e4371d8574c04a30fc3c926bc49e7",
      "c3125c187263477ea2267205500c28ee",
      "2895a2e4f94c47148e2acb1dfb2931b7",
      "646f95f6a516407f966d0533c7f6a751",
      "802ba1c9d2534f1083fdad4acedbf2a3",
      "b8270a943b224e28ac30ae67934e0864",
      "aef39e4adb1b4160909247517e47e368",
      "6ddf919930a948c1af332e98de7bc773",
      "743f855974d74812b777e0de8109e925",
      "52df5992cfdd478680633b2411cd785a",
      "2adb905b25a148e38adfbd5656c80038",
      "c540e98dfc644b39ad79b86c9d12c90f",
      "644ee57c100d449b8e5e7b834f721bc0",
      "144d89f479a540388ec3b613289f2c30",
      "8b0dae2f53864178b4663216f0ad4eb5",
      "d8709fdbf044498d9ad783680870a398",
      "0e2d968ff9784080904ab38260b7433e",
      "6df1cc29df934e0ab7dbae74567b104e",
      "bab7737bb62b46c38b788ffc232a9b88",
      "e0085c26e3de4ea8833bfc23848ba49b",
      "18e122de66704638bc502407ace9666c",
      "f87d1d640a72450e847de2d7d1280772",
      "2d02fe6d50ea45c9bd1a0141fade48c4",
      "91e0e27606c6434186dd600cd43b242e",
      "9fb7cd68c3a44a0c93e112b7d2dfd75d",
      "cc73569a53764731808640d3768cd2fb",
      "85e0250bd41d4cf284ede712e3fc6394",
      "2649f3c9d8a142469fb809dac4412470",
      "7d52261ea65142589299439e501a18f6",
      "8b3ce87553c149a1b7e718cff934797d",
      "d78ccea45a9c48f3bc509cbdc6e05231",
      "4edba2e7e6f149a9ae08dc94a70681bf",
      "4b397c0c00724d598fa8327602d068e7",
      "81ca76752c1c40ecb857b24d73efd41a",
      "3beaaec28fc54b7dbf25489954c238e0",
      "a56db593085f4794a72c1fa7c89323b7",
      "fc6c9265ce0a4d58808b0a7acda3f0f8",
      "168c4cb79f9c41209caf380044ae0620",
      "a6fda627e4df4c7d994bfac8f22bb8e0",
      "6a42ca1bf04f4f9685eaa0fcb75efd81",
      "0abd9431ad084ec4859da73c722c7b79",
      "a953c62b48d44014ab485decad5d2263",
      "3bf925c4420d438e96cf5844804a963e",
      "2ab992d1497045139cf67290a86b3dc0",
      "d4ab03d9fe5a421e9acf07da9797ad85"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428492911,
     "user_tz": -120,
     "elapsed": 2176205,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "143cf6dd-8fef-40ce-8e4d-99c1aa73e469"
   },
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel('distilbert', 'distilbert-base-cased', args={'fp16': False, 'num_train_epochs': 3, \"overwrite_output_dir\":True}) # You can set class weights by using the optional weight argument\n",
    "\n",
    "# Train the model\n",
    "model.train_model(X_train_all)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd88964febac457cbf62593f5fe10057",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7644cce1a134f6a8847984b9b9d5f66",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263273408.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d12d908d62646eb8a95c7493185ab1c",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:270: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8270a943b224e28ac30ae67934e0864",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20712.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144d89f479a540388ec3b613289f2c30",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87d1d640a72450e847de2d7d1280772",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0', max=2589.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.664165"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.655913"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.037160\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3ce87553c149a1b7e718cff934797d",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1', max=2589.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.195064\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168c4cb79f9c41209caf380044ae0620",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2', max=2589.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.001831\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IMw6mBUziwFA",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "24d689994f544a0486078887aa02795b",
      "a4864da120784b7eaf44eb76e6da7299",
      "50e5a5cb6aa34d8fa9f7d0aabcf4dcec",
      "f42fbd3baf44423193e8477ac07bc6be",
      "fbce3518cd4341998c9289c7579cdecf",
      "5f0866403d2a43288b4ea5f2abdf2409",
      "74b1bc9e969e4d5cae577ddc927edc9f",
      "533f94a5df8947e194c0f9b5a49fed54",
      "ed490a39cda34b30ab8c4a9a63ef66ab",
      "2bc29204f8f84b5d822679531ecac741",
      "e2783afc7096401583276f8cfcd09ba8",
      "8f1df001d6ce4be290ae646dbb96d391",
      "6d4881a5aa0c44ff934be278022b9a25",
      "37f54899f3a24ed8b199f6094c27452a",
      "b61c49ea32eb4d21a6d783168fadc0e2",
      "266798ed8e4a4f1880e0931143c12c98"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428512147,
     "user_tz": -120,
     "elapsed": 2195435,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "d8b5eb07-4d4b-496c-ce3e-535e9890fdd0"
   },
   "source": [
    "# Evaluate the model\n",
    "import sklearn\n",
    "result, model_outputs, wrong_predictions = model.eval_model(X_test_all, acc=sklearn.metrics.accuracy_score, f1=sklearn.metrics.f1_score)"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:691: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d689994f544a0486078887aa02795b",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2558.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed490a39cda34b30ab8c4a9a63ef66ab",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=320.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o7svswrNjIjK",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428512148,
     "user_tz": -120,
     "elapsed": 2195430,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "78303d31-ca64-4353-ece4-ddbfcc3f93d6"
   },
   "source": [
    "result"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'acc': 0.8858483189992181,\n",
       " 'eval_loss': 0.5418539448641241,\n",
       " 'f1': 0.8853102906520031,\n",
       " 'fn': 153,\n",
       " 'fp': 139,\n",
       " 'mcc': 0.7717446866552833,\n",
       " 'tn': 1139,\n",
       " 'tp': 1127}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HIR3WEA1XMw7",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "85ca0282d588406a854529aa3db74876",
      "523743570f3c44b59d93d6ad9a83038c",
      "d48d155e7b684b4e91b1deee2814add2",
      "a55f6eddd7c94834865dd0d25af4b769",
      "08b14cfd1ba54d77a3d9db11781f2fe1",
      "ad4c8f6d68ba44599f08f338d034f025",
      "b610f9d5e3f34df8b14d0fbb53ccd503",
      "63d29b172feb4cb899148e109bf3ab0b",
      "b168db505f5d435aad477d44408eb7cf",
      "2026c9667b4b480e912ee75b86d33150",
      "86e1f4d8f4994ae590191113b6ffcc98",
      "dbc466493677488badac79ed4e0f037c",
      "eee6c7456a8f43528764de2a88eb68be",
      "6f1e05208aee49abb5ec88385eff8eda",
      "27e51556c326477f8868b912bea14170",
      "2900fa22d63447e183dd692dd1987b96"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428531408,
     "user_tz": -120,
     "elapsed": 2214685,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "790870aa-44ab-44ca-a357-3cd87fc1df3e"
   },
   "source": [
    "predictions = model.predict(X_test_all[\"text\"])[0]"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ca0282d588406a854529aa3db74876",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2558.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b168db505f5d435aad477d44408eb7cf",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kQh7M9FWclnE",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428531646,
     "user_tz": -120,
     "elapsed": 2214917,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictionLabels = [dictLabelsReverse[t] for t in predictions]\n",
    "dfResults = pd.DataFrame(predictionLabels, columns=[\"prediction\"])\n",
    "dfResults[\"gold\"] = dfTest[[\"account.type\"]]\n",
    "file_name = resultsDir+\"/distillbert_finetuning.csv\"\n",
    "dfResults.to_csv(file_name, sep='\\t', encoding='utf-8')"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cGwuVWcsaZse",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428531648,
     "user_tz": -120,
     "elapsed": 2214914,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "dfTest[\"label_distillbert\"] = [dictLabelsReverse[t] for t in predictions]"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5z4JICTNSTbX",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428531649,
     "user_tz": -120,
     "elapsed": 2214909,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "def plotErrorRatio(X_test_all, prediction_column, min_sample_num=30):\n",
    "  X_verify = X_test_all[[\"screen_name\", \"text\", \"account.type\", prediction_column]]\n",
    "  X_count_accounts = X_test_all[[\"screen_name\", \"account.type\"]].groupby(\"screen_name\").count()\n",
    "  X_verify = X_verify[X_verify[\"account.type\"] != X_verify[prediction_column]]\n",
    "  X_verify = X_verify.groupby(\"screen_name\").count()[\"text\"].to_frame()\n",
    "  X_verify[\"total\"] = X_count_accounts[\"account.type\"]\n",
    "  X_verify.columns = [\"errors\", \"num_samples\"]\n",
    "  X_verify[\"error_ratio\"] = X_verify[\"errors\"] / X_verify[\"num_samples\"]\n",
    "  X_verify[X_verify[\"num_samples\"] >= min_sample_num][\"error_ratio\"].plot.bar(figsize=(15,5))\n",
    "  return X_verify"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HkD_xLJ9zCRR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428532571,
     "user_tz": -120,
     "elapsed": 2215826,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "a312f482-3f19-447a-9869-5cda9b140752"
   },
   "source": [
    "plotErrorRatio(dfTest, \"label_distillbert\")"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>errors</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>error_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AINarendraModi</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepDrumpf</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenePark_GPT2</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gpt2Wint</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JustinTrudeau</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thorin</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilityLimb</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBoterin</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahadsheriff</th>\n",
       "      <td>16</td>\n",
       "      <td>95</td>\n",
       "      <td>0.168421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahadsheriffbot</th>\n",
       "      <td>9</td>\n",
       "      <td>95</td>\n",
       "      <td>0.094737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awhalefact</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0.085714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>botustrump</th>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calebgamman</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calebgamman2</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep_potus</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep_thorin</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dril</th>\n",
       "      <td>45</td>\n",
       "      <td>180</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dril_gpt2</th>\n",
       "      <td>69</td>\n",
       "      <td>179</td>\n",
       "      <td>0.385475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elonmusk</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2_trump</th>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>0.218182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imranye</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "      <td>0.077519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imranyebot</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>0.093023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaden</th>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>0.137255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevinhooke</th>\n",
       "      <td>2</td>\n",
       "      <td>241</td>\n",
       "      <td>0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narendramodi</th>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ninjasexparty</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsp_gpt2</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realDonaldTrump</th>\n",
       "      <td>8</td>\n",
       "      <td>129</td>\n",
       "      <td>0.062016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarcastic_trump</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theJadenTrudeau</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>0.038835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whalefakes</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0.085714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zawarbot</th>\n",
       "      <td>15</td>\n",
       "      <td>152</td>\n",
       "      <td>0.098684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zawvrk</th>\n",
       "      <td>23</td>\n",
       "      <td>152</td>\n",
       "      <td>0.151316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 errors  num_samples  error_ratio\n",
       "screen_name                                      \n",
       "AINarendraModi        1          125     0.008000\n",
       "DeepDrumpf            1           29     0.034483\n",
       "GenePark_GPT2         5           22     0.227273\n",
       "Gpt2Wint              1            2     0.500000\n",
       "JustinTrudeau         1           51     0.019608\n",
       "Thorin                2           10     0.200000\n",
       "UtilityLimb           3            4     0.750000\n",
       "VBoterin              1           13     0.076923\n",
       "ahadsheriff          16           95     0.168421\n",
       "ahadsheriffbot        9           95     0.094737\n",
       "awhalefact            3           35     0.085714\n",
       "botustrump            6           35     0.171429\n",
       "calebgamman           6           13     0.461538\n",
       "calebgamman2          4           13     0.307692\n",
       "deep_potus            1            3     0.333333\n",
       "deep_thorin           2           10     0.200000\n",
       "dril                 45          180     0.250000\n",
       "dril_gpt2            69          179     0.385475\n",
       "elonmusk              2            6     0.333333\n",
       "gpt2_trump           12           55     0.218182\n",
       "imranye              10          129     0.077519\n",
       "imranyebot           12          129     0.093023\n",
       "jaden                 7           51     0.137255\n",
       "kevinhooke            2          241     0.008299\n",
       "narendramodi          1          124     0.008065\n",
       "ninjasexparty        10           23     0.434783\n",
       "nsp_gpt2              6           23     0.260870\n",
       "realDonaldTrump       8          129     0.062016\n",
       "sarcastic_trump       1            5     0.200000\n",
       "theJadenTrudeau       4          103     0.038835\n",
       "whalefakes            3           35     0.085714\n",
       "zawarbot             15          152     0.098684\n",
       "zawvrk               23          152     0.151316"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 20
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MFxq59MLEtkh",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595428532572,
     "user_tz": -120,
     "elapsed": 2215820,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    ""
   ],
   "execution_count": 20,
   "outputs": []
  }
 ]
}