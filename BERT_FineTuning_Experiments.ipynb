{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "BERT_FineTuning_Experiments.ipynb",
   "provenance": [
    {
     "file_id": "1UYNHNkk5Yq_dgIhRiVEFiswGzUJ-pdgs",
     "timestamp": 1583167071972
    }
   ],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyO+jmyFSpiVLbpFdLZIpgXO"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0724f8d989ab4fe0821250f40ca53430": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_b2fb76f1213541c4b368c49003ee5d8a",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_8f79bab0b2704120867cdd51847111c5",
       "IPY_MODEL_b02f6dbeb7d046ecadd47176245f6751"
      ]
     }
    },
    "b2fb76f1213541c4b368c49003ee5d8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "8f79bab0b2704120867cdd51847111c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_c0394c165a4943359b5c59f85cd8b9d6",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 433,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 433,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_0109e84a3d1a424996eceecd6e9d46bd"
     }
    },
    "b02f6dbeb7d046ecadd47176245f6751": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_ec3346a0e47841f696a88e8c5ff476e8",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 433/433 [00:10&lt;00:00, 40.5B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_4f108a86ec8e4b909902bd0bb86ad074"
     }
    },
    "c0394c165a4943359b5c59f85cd8b9d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "0109e84a3d1a424996eceecd6e9d46bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ec3346a0e47841f696a88e8c5ff476e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "4f108a86ec8e4b909902bd0bb86ad074": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "438d4ace3de44de089b24b805bc5e3c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_646e623e0ef242f5a6530f0c7b7600c4",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_e09301897b0b4274b4829201fed93ffd",
       "IPY_MODEL_c209ec4e0c5d4a4aaa40fd98d7c43ef6"
      ]
     }
    },
    "646e623e0ef242f5a6530f0c7b7600c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e09301897b0b4274b4829201fed93ffd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_84a76b888bdd41f9b2fbf8733ebc0403",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 435779157,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 435779157,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_8fdb3c54b3c4449a85cb3ffd20159fca"
     }
    },
    "c209ec4e0c5d4a4aaa40fd98d7c43ef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_80d9bf7738254c209a56eea3e90bbbf7",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 436M/436M [00:10&lt;00:00, 41.7MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_037a2b3345d34435aab091ad27e152a2"
     }
    },
    "84a76b888bdd41f9b2fbf8733ebc0403": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "8fdb3c54b3c4449a85cb3ffd20159fca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "80d9bf7738254c209a56eea3e90bbbf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "037a2b3345d34435aab091ad27e152a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "abe21baecf0745ca8218ba95fab008e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_5d5ee0d227fb4063ba0e87fc2e75a6a0",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_33c6354b8b1a4c1aaac7d35191ddd9da",
       "IPY_MODEL_17c71a2d9bec4263961b9bfc3519e5d4"
      ]
     }
    },
    "5d5ee0d227fb4063ba0e87fc2e75a6a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "33c6354b8b1a4c1aaac7d35191ddd9da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_4963f8551a0543b19510582d0190a27e",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 213450,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 213450,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ad86682f185e44f6a4242e9de89420e3"
     }
    },
    "17c71a2d9bec4263961b9bfc3519e5d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d896673fc1924368b0896536f610c6d9",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 213k/213k [00:00&lt;00:00, 1.41MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_2ecad657276d4ccaa2bb3a1fd645e1c2"
     }
    },
    "4963f8551a0543b19510582d0190a27e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ad86682f185e44f6a4242e9de89420e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d896673fc1924368b0896536f610c6d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "2ecad657276d4ccaa2bb3a1fd645e1c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "476bdd6d0b7e4305a1f049c02573386b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_16f28cbd18eb4adca0371c7cc09a1572",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_8ae3bb514c504687a4514de487fdb4a7",
       "IPY_MODEL_316d71f444ea431cbb87a357928b4380"
      ]
     }
    },
    "16f28cbd18eb4adca0371c7cc09a1572": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "8ae3bb514c504687a4514de487fdb4a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_238378ced95c4e3fadf186dc4545ff41",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 20712,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 20712,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_b74884e0577e40cab7d8e1558387ea2d"
     }
    },
    "316d71f444ea431cbb87a357928b4380": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_b8355f8fdaf34e87962698e966eb9df2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 20712/20712 [53:28&lt;00:00,  6.46it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_92bfbbb0e6f5477aaefd45d91287e0bd"
     }
    },
    "238378ced95c4e3fadf186dc4545ff41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "b74884e0577e40cab7d8e1558387ea2d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b8355f8fdaf34e87962698e966eb9df2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "92bfbbb0e6f5477aaefd45d91287e0bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c2c0319642b1420b9f5f99b1c0bff173": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_36f475eac0954c0d8d490f1916a001df",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_7e21eda19df2489eb8808357b844e8b2",
       "IPY_MODEL_9bbd65cd8d5647e588b5463fcb141b72"
      ]
     }
    },
    "36f475eac0954c0d8d490f1916a001df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "7e21eda19df2489eb8808357b844e8b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_fcb137d3349640fcae19e9d649d6bfa0",
      "_dom_classes": [],
      "description": "Epoch 3 of 3: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 3,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 3,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_88a38671b51146afb22ebfef285604c9"
     }
    },
    "9bbd65cd8d5647e588b5463fcb141b72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_02b2b615d88247668c056f51e260f94e",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 3/3 [53:15&lt;00:00, 1065.09s/it]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_62b2407adaaa4f22a6cc26928ab8cfd5"
     }
    },
    "fcb137d3349640fcae19e9d649d6bfa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "88a38671b51146afb22ebfef285604c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "02b2b615d88247668c056f51e260f94e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "62b2407adaaa4f22a6cc26928ab8cfd5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a9b8cb7fb8194c668e4550de8f8a0c29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d5f81de458954f53b51c7be793fb69f5",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_b1b0a7151bce41febd4a5e1a9775be8c",
       "IPY_MODEL_7c48ea2fc9954283adefcd3bc9ddb18b"
      ]
     }
    },
    "d5f81de458954f53b51c7be793fb69f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b1b0a7151bce41febd4a5e1a9775be8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_3f7c15aa4abf4405ac72914c8e22419e",
      "_dom_classes": [],
      "description": "Running Epoch 0: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_8dc7c8af2bfb471ba8a78b6bcc5b6279"
     }
    },
    "7c48ea2fc9954283adefcd3bc9ddb18b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_b03a6ea7e24241778942c7bfc30162a4",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [53:15&lt;00:00,  1.23s/it]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_cf1d058c7c04499baf71e705088bbf8a"
     }
    },
    "3f7c15aa4abf4405ac72914c8e22419e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "8dc7c8af2bfb471ba8a78b6bcc5b6279": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b03a6ea7e24241778942c7bfc30162a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "cf1d058c7c04499baf71e705088bbf8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c416afdfba504ba5b32ff8741c64c983": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_676dab4c76a5403689b1e2ad83614fad",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_f70c04eaa2954a8d85f12b725e459517",
       "IPY_MODEL_edaf2d0503c14fddb2029ff26d345a6a"
      ]
     }
    },
    "676dab4c76a5403689b1e2ad83614fad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f70c04eaa2954a8d85f12b725e459517": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_c7814420f169494d960f41f0f18c2cbe",
      "_dom_classes": [],
      "description": "Running Epoch 1: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_5e3aa16ed9ea496aa7eeb4c643587e8f"
     }
    },
    "edaf2d0503c14fddb2029ff26d345a6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_8a638118cb884a01bb84e06c76382da2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [35:40&lt;00:00,  1.21it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ab739773754c4e5cac7d99e1a338b996"
     }
    },
    "c7814420f169494d960f41f0f18c2cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "5e3aa16ed9ea496aa7eeb4c643587e8f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "8a638118cb884a01bb84e06c76382da2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ab739773754c4e5cac7d99e1a338b996": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f2481f3fc63542d3a2da66b2b1129972": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_92a1c945a9ac4926b9a2437d91519806",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_aa63d5cc7ada4ffc80cf2e153f1bb5d2",
       "IPY_MODEL_81fa35c8d508453cbc43181a7f466d52"
      ]
     }
    },
    "92a1c945a9ac4926b9a2437d91519806": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "aa63d5cc7ada4ffc80cf2e153f1bb5d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_60bc3d52bda441d78ac97bd08cab58a3",
      "_dom_classes": [],
      "description": "Running Epoch 2: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_2f5221cbd3ed41988f44170006bae2ae"
     }
    },
    "81fa35c8d508453cbc43181a7f466d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_a9aa2684cb644872ae73a20b18534fb2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [18:10&lt;00:00,  2.37it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_b13fac04d6d846e58578a4c8a027eda0"
     }
    },
    "60bc3d52bda441d78ac97bd08cab58a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "2f5221cbd3ed41988f44170006bae2ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a9aa2684cb644872ae73a20b18534fb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "b13fac04d6d846e58578a4c8a027eda0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "087d7ec97f79449db4c5fff1b6e14311": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_765f048a979e4af881d2e911a5c78a41",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_84724a15eb8d47a8ab1b1d8f5ee79b76",
       "IPY_MODEL_44a94eec1ef4437e81bf64ab448a6b37"
      ]
     }
    },
    "765f048a979e4af881d2e911a5c78a41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "84724a15eb8d47a8ab1b1d8f5ee79b76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_f58afb4325644b7184f36d2d1666b65f",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2558,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2558,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_b9b568d7ca2748928f4be094bfa9ad57"
     }
    },
    "44a94eec1ef4437e81bf64ab448a6b37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_2a9a73cedb7f4633bd48ba8fb11e6ec7",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2558/2558 [00:46&lt;00:00, 54.73it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_559e3185a52d4361af0d11b07c8f40ce"
     }
    },
    "f58afb4325644b7184f36d2d1666b65f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "b9b568d7ca2748928f4be094bfa9ad57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2a9a73cedb7f4633bd48ba8fb11e6ec7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "559e3185a52d4361af0d11b07c8f40ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f87743892d574e64952861a6ff9b9528": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_00b800fbfd5a4cfc99eeb5e9a538c178",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_12ff0c882ca74bc8a18c44944146b38b",
       "IPY_MODEL_044f4330fb1f4058aafcb213c2f9ca65"
      ]
     }
    },
    "00b800fbfd5a4cfc99eeb5e9a538c178": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "12ff0c882ca74bc8a18c44944146b38b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_12b4bfa146cf4fc6a1f263eb3a4d595e",
      "_dom_classes": [],
      "description": "Running Evaluation: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 320,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 320,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_20acdffb687d4063a917357d811ffc33"
     }
    },
    "044f4330fb1f4058aafcb213c2f9ca65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d60a976b7e3647edbbbe72d891c3de3a",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 320/320 [00:38&lt;00:00,  8.30it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_a1fc355178b84458b946d893a42c6fce"
     }
    },
    "12b4bfa146cf4fc6a1f263eb3a4d595e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "20acdffb687d4063a917357d811ffc33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d60a976b7e3647edbbbe72d891c3de3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "a1fc355178b84458b946d893a42c6fce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2189fc4021204dbd89505751993d399d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_7b3f5d66b54e448198e433ddee823989",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_ff8bacbdffb84097bd48940de9f94eb1",
       "IPY_MODEL_98ac47e093e2464ca3a03fd9f684f310"
      ]
     }
    },
    "7b3f5d66b54e448198e433ddee823989": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ff8bacbdffb84097bd48940de9f94eb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_7c40c7137ddc4b81b41b293ee3aa6b19",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2558,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2558,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_bef42ac6d7c440928b57bacdf475b477"
     }
    },
    "98ac47e093e2464ca3a03fd9f684f310": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_41ae9ee84f5d41db9e18ad20c7cacc6d",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2558/2558 [00:01&lt;00:00, 1742.87it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_53944834290e48b5bcb96e7fd69b5c27"
     }
    },
    "7c40c7137ddc4b81b41b293ee3aa6b19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "bef42ac6d7c440928b57bacdf475b477": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "41ae9ee84f5d41db9e18ad20c7cacc6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "53944834290e48b5bcb96e7fd69b5c27": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "df42fe2cf6914ba981c85fccf7ae30a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_95bd156e2b5a451aa9472209a53b7682",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_16f19cf78f1142fc8cfe118cd1dc7248",
       "IPY_MODEL_2bd25ccd86474a85ac4009a4ff7afcd1"
      ]
     }
    },
    "95bd156e2b5a451aa9472209a53b7682": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "16f19cf78f1142fc8cfe118cd1dc7248": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_b1150e4a008d4ccabc645f51928d3400",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 320,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 320,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_496f21c8b5b1492bb752734a4c5535ae"
     }
    },
    "2bd25ccd86474a85ac4009a4ff7afcd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_274bfde0baca482d8e215956e4dc3258",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 320/320 [00:38&lt;00:00,  8.33it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_70c66ebbe0124bd182884bdda2607102"
     }
    },
    "b1150e4a008d4ccabc645f51928d3400": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "496f21c8b5b1492bb752734a4c5535ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "274bfde0baca482d8e215956e4dc3258": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "70c66ebbe0124bd182884bdda2607102": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "YDHCjaH5QrDk",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595421594406,
     "user_tz": -120,
     "elapsed": 25611,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "ec5b1c6c-738e-419a-8a88-b8e8683a2c3d"
   },
   "source": [
    "#%tensorflow_version 2.x\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_t6gg1ZLRYxS",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595421594408,
     "user_tz": -120,
     "elapsed": 25609,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "import sys\n",
    "projectDir = \"/content/drive/My Drive/code/git/tweepfake_deepfake_text_detection\"\n",
    "sys.path.insert(0, projectDir)\n",
    "\n",
    "random_state = 523 # Fixed seed for replicability of randomic operations.\n",
    "resultsDir = projectDir+\"/data/results\""
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DuMYSMSjTjdr",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595421594409,
     "user_tz": -120,
     "elapsed": 25579,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "06d70ee9-9a4d-4761-9d02-e7ff1891dbca"
   },
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "export CUDA_HOME=/usr/local/cuda-10.1\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Writing setup.sh\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sW5qeRXxVQMB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422170027,
     "user_tz": -120,
     "elapsed": 601190,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "90f507dc-6983-46af-a3d9-fba7891f6cba"
   },
   "source": [
    "!sh setup.sh"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 14, done.\u001B[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001B[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001B[K\n",
      "remote: Total 7367 (delta 3), reused 0 (delta 0), pack-reused 7353\u001B[K\n",
      "Receiving objects: 100% (7367/7367), 13.89 MiB | 19.35 MiB/s, done.\n",
      "Resolving deltas: 100% (4974/4974), done.\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-k5khu51o\n",
      "Created temporary directory: /tmp/pip-req-tracker-mgs9yhyt\n",
      "Created requirements tracker '/tmp/pip-req-tracker-mgs9yhyt'\n",
      "Created temporary directory: /tmp/pip-install-0v7o79nh\n",
      "Processing ./apex\n",
      "  Created temporary directory: /tmp/pip-req-build-gn57l9u2\n",
      "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-mgs9yhyt'\n",
      "    Running setup.py (path:/tmp/pip-req-build-gn57l9u2/setup.py) egg_info for package from file:///content/apex\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.1+cu101\n",
      "\n",
      "\n",
      "    running egg_info\n",
      "    creating /tmp/pip-req-build-gn57l9u2/pip-egg-info/apex.egg-info\n",
      "    writing /tmp/pip-req-build-gn57l9u2/pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-req-build-gn57l9u2/pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-req-build-gn57l9u2/pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-req-build-gn57l9u2/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file '/tmp/pip-req-build-gn57l9u2/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-gn57l9u2/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Source in /tmp/pip-req-build-gn57l9u2 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
      "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-mgs9yhyt'\n",
      "Skipping wheel build for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-vnnum7ag\n",
      "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-gn57l9u2/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-gn57l9u2/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-vnnum7ag/install-record.txt --single-version-externally-managed --compile\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.1+cu101\n",
      "\n",
      "\n",
      "    /tmp/pip-req-build-gn57l9u2/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "    Cuda compilation tools, release 10.1, V10.1.243\n",
      "    from /usr/local/cuda-10.1/bin\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
      "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
      "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    running build_ext\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "      warnings.warn(msg.format('we could not find ninja.'))\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         return tensors[0].type();\n",
      "                                ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/flatten_unflatten.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    building 'syncbn' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_layer_norm_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(gamma);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(beta);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(dout);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(mean);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(invvar);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(dout);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(mean);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(invvar);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(gamma);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n",
      "       CHECK_INPUT(beta);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'mlp_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
      "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < num_layers; i++) {\n",
      "                       ~~^~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
      "                                                                                 ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                        ^\n",
      "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "                                                          ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "         const auto& the_type = TYPE;                                             \\\n",
      "                                ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                            ^\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
      "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < num_layers; i++) {\n",
      "                       ~~^~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < inputs.size(); i++) {\n",
      "                       ~~^~~~~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
      "                                                                       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "                                                          ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "         const auto& the_type = TYPE;                                             \\\n",
      "                                ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                            ^\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    running install_lib\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
      "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "    running install_egg_info\n",
      "    running egg_info\n",
      "    creating apex.egg-info\n",
      "    writing apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to apex.egg-info/top_level.txt\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
      "    running install_scripts\n",
      "    writing list of installed files to '/tmp/pip-record-vnnum7ag/install-record.txt'\n",
      "    Running setup.py install for apex ... \u001B[?25l\u001B[?25hdone\n",
      "  Removing source in /tmp/pip-req-build-gn57l9u2\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "Removed build tracker '/tmp/pip-req-tracker-mgs9yhyt'\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XqnRBYPkcx_g",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422170028,
     "user_tz": -120,
     "elapsed": 601188,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    ""
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V3qW3001RonB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 970
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422417731,
     "user_tz": -120,
     "elapsed": 5514,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "6f1b5b6c-519a-4083-d7ee-ab34f01febce"
   },
   "source": [
    "!pip install pandas transformers simpletransformers==0.41 amp"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
      "Collecting simpletransformers==0.41\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/99/0d/4e3d32c543e340a52dfbf908b1cc2dea16b605ba0c67a6fb39654c73d555/simpletransformers-0.41.0-py3-none-any.whl (191kB)\n",
      "\u001B[K     |████████████████████████████████| 194kB 3.1MB/s \n",
      "\u001B[?25hRequirement already satisfied: amp in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from simpletransformers==0.41) (0.0.12)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from simpletransformers==0.41) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simpletransformers==0.41) (1.4.1)\n",
      "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (from simpletransformers==0.41) (2.1)\n",
      "Requirement already satisfied: caldav==0.1.4 in /usr/local/lib/python3.6/dist-packages (from amp) (0.1.4)\n",
      "Requirement already satisfied: Django>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from amp) (3.0.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->simpletransformers==0.41) (2.3.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers==0.41) (3.12.2)\n",
      "Requirement already satisfied: vobject in /usr/local/lib/python3.6/dist-packages (from caldav==0.1.4->amp) (0.9.6.1)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from caldav==0.1.4->amp) (4.2.6)\n",
      "Requirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from caldav==0.1.4->amp) (3.7.1)\n",
      "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from caldav==0.1.4->amp) (1.3.7)\n",
      "Requirement already satisfied: asgiref~=3.2 in /usr/local/lib/python3.6/dist-packages (from Django>=1.1.1->amp) (3.2.10)\n",
      "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from Django>=1.1.1->amp) (0.3.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers==0.41) (49.1.0)\n",
      "\u001B[31mERROR: simpletransformers 0.41.0 has requirement tokenizers<=0.7, but you'll have tokenizers 0.8.1rc1 which is incompatible.\u001B[0m\n",
      "Installing collected packages: simpletransformers\n",
      "  Found existing installation: simpletransformers 0.45.0\n",
      "    Uninstalling simpletransformers-0.45.0:\n",
      "      Successfully uninstalled simpletransformers-0.45.0\n",
      "Successfully installed simpletransformers-0.41.0\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "simpletransformers"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lLsNhiofRy5r",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422417996,
     "user_tz": -120,
     "elapsed": 5770,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "from DataHandler import DataHandler\n",
    "\n",
    "csvTrainDataset = projectDir+\"/data/splits/train.csv\"\n",
    "csvValDataset = projectDir+\"/data/splits/validation.csv\"\n",
    "csvTestDataset = projectDir+\"/data/splits/test.csv\"\n",
    "\n",
    "bertDir = projectDir+\"/data/encoded/bert\"\n",
    "dh = DataHandler()\n",
    "dfTrain = dh.readCSVData(csvTrainDataset)\n",
    "dfVal = dh.readCSVData(csvValDataset)\n",
    "dfTest = dh.readCSVData(csvTestDataset)"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mBCDg773SZKW",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422418282,
     "user_tz": -120,
     "elapsed": 6050,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "f6e047db-c784-48ed-d6b6-36c46d463f8f"
   },
   "source": [
    "dfTrain"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_prog</th>\n",
       "      <th>user_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>symbols</th>\n",
       "      <th>urls_url</th>\n",
       "      <th>urls_t.co</th>\n",
       "      <th>urls_expanded_url</th>\n",
       "      <th>media_url</th>\n",
       "      <th>media_t.co</th>\n",
       "      <th>media_expanded_url</th>\n",
       "      <th>media_type</th>\n",
       "      <th>ext_media_url</th>\n",
       "      <th>ext_media_t.co</th>\n",
       "      <th>ext_media_expanded_url</th>\n",
       "      <th>ext_media_type</th>\n",
       "      <th>mentions_user_id</th>\n",
       "      <th>mentions_screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_text</th>\n",
       "      <th>quoted_created_at</th>\n",
       "      <th>quoted_source</th>\n",
       "      <th>quoted_favorite_count</th>\n",
       "      <th>quoted_retweet_count</th>\n",
       "      <th>quoted_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>place_url</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_coords</th>\n",
       "      <th>coords_coords</th>\n",
       "      <th>bbox_coords</th>\n",
       "      <th>status_url</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>protected</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>profile_url</th>\n",
       "      <th>profile_expanded_url</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>profile_banner_url</th>\n",
       "      <th>profile_background_url</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>created</th>\n",
       "      <th>data.tweet</th>\n",
       "      <th>ora.tweet</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>mention_TF</th>\n",
       "      <th>hashtag_TF</th>\n",
       "      <th>url_TF</th>\n",
       "      <th>n.words</th>\n",
       "      <th>punct</th>\n",
       "      <th>account.type</th>\n",
       "      <th>finetuning_source</th>\n",
       "      <th>class_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14692</td>\n",
       "      <td>x1110407881030017024</td>\n",
       "      <td>x1208265880146046976</td>\n",
       "      <td>2019-12-21 06:00:08</td>\n",
       "      <td>imranyebot</td>\n",
       "      <td>YEA now that note GOOD</td>\n",
       "      <td>imranye-twitter-bot</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/imranyebot/status/12082658...</td>\n",
       "      <td>imranyebot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@imranye in robot form. tweets every hour gene...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7467</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-26 05:07:23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1110408254...</td>\n",
       "      <td>2019-12-21 06:00:08</td>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>06:00:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>imranye</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22336</td>\n",
       "      <td>x3171109449</td>\n",
       "      <td>x1091463908118941696</td>\n",
       "      <td>2019-02-01 22:30:48</td>\n",
       "      <td>zawvrk</td>\n",
       "      <td>Listen to This Charming Man by The Smiths  htt...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>soundcloud.com/thesmiths/this…</td>\n",
       "      <td>https://t.co/r12OIXkfUO</td>\n",
       "      <td>https://soundcloud.com/thesmiths/this-charming...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/zawvrk/status/109146390811...</td>\n",
       "      <td>zawar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gold experience</td>\n",
       "      <td>https://t.co/J60plTSsKt</td>\n",
       "      <td>False</td>\n",
       "      <td>558</td>\n",
       "      <td>274</td>\n",
       "      <td>8</td>\n",
       "      <td>12216</td>\n",
       "      <td>23633</td>\n",
       "      <td>2015-04-15 19:50:16</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/J60plTSsKt</td>\n",
       "      <td>https://www.instagram.com/zawvr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/31711094...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1229957200...</td>\n",
       "      <td>2019-02-01 22:30:48</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>22:30:48</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>human</td>\n",
       "      <td>original</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24087</td>\n",
       "      <td>x1110686081341632512</td>\n",
       "      <td>x1199055191028293633</td>\n",
       "      <td>2019-11-25 20:00:09</td>\n",
       "      <td>zawarbot</td>\n",
       "      <td>wish i can i would be seeing other hoes on the...</td>\n",
       "      <td>zawar-twitter-bot</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/zawarbot/status/1199055191...</td>\n",
       "      <td>zawarbot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I’m an AI Bot that tries to tweet like @zawvrk...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4054</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-03-26 23:32:52</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1185589257...</td>\n",
       "      <td>2019-11-25 20:00:09</td>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>20:00:09</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>zawvrk</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7584</td>\n",
       "      <td>x1110307772783124480</td>\n",
       "      <td>x1214698264701722626</td>\n",
       "      <td>2020-01-08 00:00:08</td>\n",
       "      <td>ahadsheriffbot</td>\n",
       "      <td>The decade in the significantly easier schedul...</td>\n",
       "      <td>ahadsheriff-bot</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/ahadsheriffbot/status/1214...</td>\n",
       "      <td>Robot Ahad Sheriff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@ahadsheriff in robot form. tweets every hour ...</td>\n",
       "      <td>https://t.co/2G243YsNOt</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7946</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-25 22:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/2G243YsNOt</td>\n",
       "      <td>https://ahadsheriff.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1110311752...</td>\n",
       "      <td>2020-01-08 00:00:08</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>00:00:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>bot</td>\n",
       "      <td>ahadsheriff</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19654</td>\n",
       "      <td>x979586167405363200</td>\n",
       "      <td>x1209229478934695937</td>\n",
       "      <td>2019-12-23 21:49:08</td>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Theim class=\\\"alignnone size-full wp-image-60...</td>\n",
       "      <td>kevinhooke-ml-bot</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kevinhooke.com/wp-content/upl…</td>\n",
       "      <td>https://t.co/LiAsQsbs99</td>\n",
       "      <td>https://www.kevinhooke.com/wp-content/uploads/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/kevinhookebot/status/12092...</td>\n",
       "      <td>Kevin Hooke Bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm an AWS Lambda generating content from a Re...</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6608</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 05:08:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>https://www.kevinhooke.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/sticky/default_profile_im...</td>\n",
       "      <td>2019-12-23 21:49:08</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>21:49:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>bot</td>\n",
       "      <td>kevinhooke</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20707</th>\n",
       "      <td>1538</td>\n",
       "      <td>x1197916267975335939</td>\n",
       "      <td>x1204245032917700608</td>\n",
       "      <td>2019-12-10 03:42:44</td>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Met on the Abversion of our science for the co...</td>\n",
       "      <td>AI_Narendra_Modi</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>life.Om</td>\n",
       "      <td>https://t.co/kl5Dfl0y18</td>\n",
       "      <td>http://life.Om</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/AINarendraModi/status/1204...</td>\n",
       "      <td>AI Narendra Modi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Narendra Modi but with AI\\r\\nBot commands - ht...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-22 16:34:45</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/11979162...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1197916520...</td>\n",
       "      <td>2019-12-10 03:42:44</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>03:42:44</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>bot</td>\n",
       "      <td>narendramodi</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>1885</td>\n",
       "      <td>x1197916267975335939</td>\n",
       "      <td>x1207011474243309570</td>\n",
       "      <td>2019-12-17 18:55:35</td>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Land for their during the opportunity to the p...</td>\n",
       "      <td>AI_Narendra_Modi</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/AINarendraModi/status/1207...</td>\n",
       "      <td>AI Narendra Modi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Narendra Modi but with AI\\r\\nBot commands - ht...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-22 16:34:45</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/11979162...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1197916520...</td>\n",
       "      <td>2019-12-17 18:55:35</td>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>18:55:35</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>bot</td>\n",
       "      <td>narendramodi</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20709</th>\n",
       "      <td>3930</td>\n",
       "      <td>x705113652471439361</td>\n",
       "      <td>x715558455285837824</td>\n",
       "      <td>2016-03-31 15:16:44</td>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>@TayandYou doesn't have a clue. You're right. ...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>133</td>\n",
       "      <td>x714838749860012032</td>\n",
       "      <td>x78324623</td>\n",
       "      <td>eldiariodedross</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x4531940473 x78324623</td>\n",
       "      <td>TayandYou eldiariodedross</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/DeepDrumpf/status/71555845...</td>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm a Neural Network trained on Trump's transc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>25401</td>\n",
       "      <td>7</td>\n",
       "      <td>296</td>\n",
       "      <td>286</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-03-02 19:32:49</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/70511365...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/7054647353...</td>\n",
       "      <td>2016-03-31 15:16:44</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>15:16:44</td>\n",
       "      <td>reply</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>bot</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>729</td>\n",
       "      <td>x262794965</td>\n",
       "      <td>x812868913239199745</td>\n",
       "      <td>2016-12-25 03:53:45</td>\n",
       "      <td>jaden</td>\n",
       "      <td>Me And My Bestie https://t.co/vPq2iDkWZm</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7265</td>\n",
       "      <td>1071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/media/C0fj97lUQAAT-dC.jpg</td>\n",
       "      <td>https://t.co/vPq2iDkWZm</td>\n",
       "      <td>https://twitter.com/officialjaden/status/81286...</td>\n",
       "      <td>photo</td>\n",
       "      <td>http://pbs.twimg.com/media/C0fj97lUQAAT-dC.jpg</td>\n",
       "      <td>https://t.co/vPq2iDkWZm</td>\n",
       "      <td>https://twitter.com/officialjaden/status/81286...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/jaden/status/8128689132391...</td>\n",
       "      <td>Jaden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;U+0001F308&gt; Boy</td>\n",
       "      <td>https://t.co/2dZJOThjAQ</td>\n",
       "      <td>False</td>\n",
       "      <td>8142789</td>\n",
       "      <td>188</td>\n",
       "      <td>14893</td>\n",
       "      <td>5669</td>\n",
       "      <td>1844</td>\n",
       "      <td>2011-03-08 19:41:06</td>\n",
       "      <td>True</td>\n",
       "      <td>https://t.co/2dZJOThjAQ</td>\n",
       "      <td>https://jaden.link/erys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/26279496...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1146090110...</td>\n",
       "      <td>2016-12-25 03:53:45</td>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>03:53:45</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "      <td>original</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>19366</td>\n",
       "      <td>x979586167405363200</td>\n",
       "      <td>x1194703766303338496</td>\n",
       "      <td>2019-11-13 19:49:09</td>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Thead has a generate existing the Sparching f...</td>\n",
       "      <td>kevinhooke-ml-bot</td>\n",
       "      <td>205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/kevinhookebot/status/11947...</td>\n",
       "      <td>Kevin Hooke Bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm an AWS Lambda generating content from a Re...</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6608</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 05:08:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>https://www.kevinhooke.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/sticky/default_profile_im...</td>\n",
       "      <td>2019-11-13 19:49:09</td>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>19:49:09</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>bot</td>\n",
       "      <td>kevinhooke</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20712 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      N_prog               user_id  ... finetuning_source class_type\n",
       "0      14692  x1110407881030017024  ...           imranye     others\n",
       "1      22336           x3171109449  ...          original      human\n",
       "2      24087  x1110686081341632512  ...            zawvrk     others\n",
       "3       7584  x1110307772783124480  ...       ahadsheriff     others\n",
       "4      19654   x979586167405363200  ...        kevinhooke        rnn\n",
       "...      ...                   ...  ...               ...        ...\n",
       "20707   1538  x1197916267975335939  ...      narendramodi        rnn\n",
       "20708   1885  x1197916267975335939  ...      narendramodi        rnn\n",
       "20709   3930   x705113652471439361  ...   realDonaldTrump        rnn\n",
       "20710    729            x262794965  ...          original      human\n",
       "20711  19366   x979586167405363200  ...        kevinhooke        rnn\n",
       "\n",
       "[20712 rows x 103 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c0oedq8-W7u2",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422418283,
     "user_tz": -120,
     "elapsed": 6044,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "# Select interesting columns for this study.\n",
    "dfTrainDataset = dfTrain[[\"screen_name\", \"text\", \"account.type\"]]\n",
    "dfValDataset = dfVal[[\"screen_name\", \"text\", \"account.type\"]]\n",
    "dfTestDataset = dfTest[[\"screen_name\", \"text\", \"account.type\"]]"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qTeVpVc6I9Lb",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422418284,
     "user_tz": -120,
     "elapsed": 6040,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "161d6db5-9e44-484e-ee9c-84b80c29869d"
   },
   "source": [
    "dfTrainDataset"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>account.type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imranyebot</td>\n",
       "      <td>YEA now that note GOOD</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zawvrk</td>\n",
       "      <td>Listen to This Charming Man by The Smiths  htt...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zawarbot</td>\n",
       "      <td>wish i can i would be seeing other hoes on the...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ahadsheriffbot</td>\n",
       "      <td>The decade in the significantly easier schedul...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Theim class=\\\"alignnone size-full wp-image-60...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20707</th>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Met on the Abversion of our science for the co...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Land for their during the opportunity to the p...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20709</th>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>@TayandYou doesn't have a clue. You're right. ...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>jaden</td>\n",
       "      <td>Me And My Bestie https://t.co/vPq2iDkWZm</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Thead has a generate existing the Sparching f...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20712 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_name  ... account.type\n",
       "0          imranyebot  ...          bot\n",
       "1              zawvrk  ...        human\n",
       "2            zawarbot  ...          bot\n",
       "3      ahadsheriffbot  ...          bot\n",
       "4       kevinhookebot  ...          bot\n",
       "...               ...  ...          ...\n",
       "20707  AINarendraModi  ...          bot\n",
       "20708  AINarendraModi  ...          bot\n",
       "20709      DeepDrumpf  ...          bot\n",
       "20710           jaden  ...        human\n",
       "20711   kevinhookebot  ...          bot\n",
       "\n",
       "[20712 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yvFnZqKMIY4F",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422418284,
     "user_tz": -120,
     "elapsed": 6033,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "X_train_all = dfTrainDataset.drop(columns=['screen_name'])\n",
    "X_train_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "X_val_all = dfValDataset.drop(columns=['screen_name'])\n",
    "X_val_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "X_test_all = dfTestDataset.drop(columns=['screen_name'])\n",
    "X_test_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "dictLabels = {\"human\":0, \"bot\":1}\n",
    "dictLabelsReverse = {0:\"human\", 1: \"bot\"}\n",
    "\n",
    "X_train_all[\"label\"] = X_train_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "X_val_all[\"label\"] = X_val_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "X_test_all[\"label\"] = X_test_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "y_train = X_train_all[\"label\"]\n",
    "y_val = X_val_all[\"label\"]\n",
    "y_test = X_test_all[\"label\"]"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xDAhMIgmpxTs",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595422418285,
     "user_tz": -120,
     "elapsed": 6028,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "train_labels = y_train.tolist()\n",
    "val_labels = y_val.tolist()\n",
    "test_labels = y_test.tolist()"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QtE2szKKPis5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616,
     "referenced_widgets": [
      "0724f8d989ab4fe0821250f40ca53430",
      "b2fb76f1213541c4b368c49003ee5d8a",
      "8f79bab0b2704120867cdd51847111c5",
      "b02f6dbeb7d046ecadd47176245f6751",
      "c0394c165a4943359b5c59f85cd8b9d6",
      "0109e84a3d1a424996eceecd6e9d46bd",
      "ec3346a0e47841f696a88e8c5ff476e8",
      "4f108a86ec8e4b909902bd0bb86ad074",
      "438d4ace3de44de089b24b805bc5e3c8",
      "646e623e0ef242f5a6530f0c7b7600c4",
      "e09301897b0b4274b4829201fed93ffd",
      "c209ec4e0c5d4a4aaa40fd98d7c43ef6",
      "84a76b888bdd41f9b2fbf8733ebc0403",
      "8fdb3c54b3c4449a85cb3ffd20159fca",
      "80d9bf7738254c209a56eea3e90bbbf7",
      "037a2b3345d34435aab091ad27e152a2",
      "abe21baecf0745ca8218ba95fab008e9",
      "5d5ee0d227fb4063ba0e87fc2e75a6a0",
      "33c6354b8b1a4c1aaac7d35191ddd9da",
      "17c71a2d9bec4263961b9bfc3519e5d4",
      "4963f8551a0543b19510582d0190a27e",
      "ad86682f185e44f6a4242e9de89420e3",
      "d896673fc1924368b0896536f610c6d9",
      "2ecad657276d4ccaa2bb3a1fd645e1c2",
      "476bdd6d0b7e4305a1f049c02573386b",
      "16f28cbd18eb4adca0371c7cc09a1572",
      "8ae3bb514c504687a4514de487fdb4a7",
      "316d71f444ea431cbb87a357928b4380",
      "238378ced95c4e3fadf186dc4545ff41",
      "b74884e0577e40cab7d8e1558387ea2d",
      "b8355f8fdaf34e87962698e966eb9df2",
      "92bfbbb0e6f5477aaefd45d91287e0bd",
      "c2c0319642b1420b9f5f99b1c0bff173",
      "36f475eac0954c0d8d490f1916a001df",
      "7e21eda19df2489eb8808357b844e8b2",
      "9bbd65cd8d5647e588b5463fcb141b72",
      "fcb137d3349640fcae19e9d649d6bfa0",
      "88a38671b51146afb22ebfef285604c9",
      "02b2b615d88247668c056f51e260f94e",
      "62b2407adaaa4f22a6cc26928ab8cfd5",
      "a9b8cb7fb8194c668e4550de8f8a0c29",
      "d5f81de458954f53b51c7be793fb69f5",
      "b1b0a7151bce41febd4a5e1a9775be8c",
      "7c48ea2fc9954283adefcd3bc9ddb18b",
      "3f7c15aa4abf4405ac72914c8e22419e",
      "8dc7c8af2bfb471ba8a78b6bcc5b6279",
      "b03a6ea7e24241778942c7bfc30162a4",
      "cf1d058c7c04499baf71e705088bbf8a",
      "c416afdfba504ba5b32ff8741c64c983",
      "676dab4c76a5403689b1e2ad83614fad",
      "f70c04eaa2954a8d85f12b725e459517",
      "edaf2d0503c14fddb2029ff26d345a6a",
      "c7814420f169494d960f41f0f18c2cbe",
      "5e3aa16ed9ea496aa7eeb4c643587e8f",
      "8a638118cb884a01bb84e06c76382da2",
      "ab739773754c4e5cac7d99e1a338b996",
      "f2481f3fc63542d3a2da66b2b1129972",
      "92a1c945a9ac4926b9a2437d91519806",
      "aa63d5cc7ada4ffc80cf2e153f1bb5d2",
      "81fa35c8d508453cbc43181a7f466d52",
      "60bc3d52bda441d78ac97bd08cab58a3",
      "2f5221cbd3ed41988f44170006bae2ae",
      "a9aa2684cb644872ae73a20b18534fb2",
      "b13fac04d6d846e58578a4c8a027eda0"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425612794,
     "user_tz": -120,
     "elapsed": 3200531,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "51bbe27f-157b-4571-e08f-06bdb6373e3d"
   },
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel('bert', 'bert-base-cased', args={'fp16': False, 'num_train_epochs': 3, \"overwrite_output_dir\":True}) # You can set class weights by using the optional weight argument\n",
    "\n",
    "# Train the model\n",
    "model.train_model(X_train_all)"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0724f8d989ab4fe0821250f40ca53430",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438d4ace3de44de089b24b805bc5e3c8",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe21baecf0745ca8218ba95fab008e9",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:270: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476bdd6d0b7e4305a1f049c02573386b",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20712.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c0319642b1420b9f5f99b1c0bff173",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b8cb7fb8194c668e4550de8f8a0c29",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0', max=2589.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.636869"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.108078"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.017737\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c416afdfba504ba5b32ff8741c64c983",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1', max=2589.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.003148\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2481f3fc63542d3a2da66b2b1129972",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2', max=2589.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.001029\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IMw6mBUziwFA",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "087d7ec97f79449db4c5fff1b6e14311",
      "765f048a979e4af881d2e911a5c78a41",
      "84724a15eb8d47a8ab1b1d8f5ee79b76",
      "44a94eec1ef4437e81bf64ab448a6b37",
      "f58afb4325644b7184f36d2d1666b65f",
      "b9b568d7ca2748928f4be094bfa9ad57",
      "2a9a73cedb7f4633bd48ba8fb11e6ec7",
      "559e3185a52d4361af0d11b07c8f40ce",
      "f87743892d574e64952861a6ff9b9528",
      "00b800fbfd5a4cfc99eeb5e9a538c178",
      "12ff0c882ca74bc8a18c44944146b38b",
      "044f4330fb1f4058aafcb213c2f9ca65",
      "12b4bfa146cf4fc6a1f263eb3a4d595e",
      "20acdffb687d4063a917357d811ffc33",
      "d60a976b7e3647edbbbe72d891c3de3a",
      "a1fc355178b84458b946d893a42c6fce"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425658152,
     "user_tz": -120,
     "elapsed": 3245880,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "3e4b4351-3e88-464f-c304-a9b24685da0f"
   },
   "source": [
    "# Evaluate the model\n",
    "import sklearn\n",
    "result, model_outputs, wrong_predictions = model.eval_model(X_test_all, acc=sklearn.metrics.accuracy_score, f1=sklearn.metrics.f1_score)"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:691: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087d7ec97f79449db4c5fff1b6e14311",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2558.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87743892d574e64952861a6ff9b9528",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=320.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o7svswrNjIjK",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425658153,
     "user_tz": -120,
     "elapsed": 3245876,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "1a47578c-1476-407d-f5f4-a4ef6d5fd5f9"
   },
   "source": [
    "result"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'acc': 0.8964034401876466,\n",
       " 'eval_loss': 0.5412028348346212,\n",
       " 'f1': 0.8978805394990366,\n",
       " 'fn': 115,\n",
       " 'fp': 150,\n",
       " 'mcc': 0.7930993455960791,\n",
       " 'tn': 1128,\n",
       " 'tp': 1165}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HIR3WEA1XMw7",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "2189fc4021204dbd89505751993d399d",
      "7b3f5d66b54e448198e433ddee823989",
      "ff8bacbdffb84097bd48940de9f94eb1",
      "98ac47e093e2464ca3a03fd9f684f310",
      "7c40c7137ddc4b81b41b293ee3aa6b19",
      "bef42ac6d7c440928b57bacdf475b477",
      "41ae9ee84f5d41db9e18ad20c7cacc6d",
      "53944834290e48b5bcb96e7fd69b5c27",
      "df42fe2cf6914ba981c85fccf7ae30a3",
      "95bd156e2b5a451aa9472209a53b7682",
      "16f19cf78f1142fc8cfe118cd1dc7248",
      "2bd25ccd86474a85ac4009a4ff7afcd1",
      "b1150e4a008d4ccabc645f51928d3400",
      "496f21c8b5b1492bb752734a4c5535ae",
      "274bfde0baca482d8e215956e4dc3258",
      "70c66ebbe0124bd182884bdda2607102"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425698250,
     "user_tz": -120,
     "elapsed": 3285967,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "bf7c4fc4-9275-4e07-85ee-037127421088"
   },
   "source": [
    "predictions = model.predict(X_test_all[\"text\"])[0]"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2189fc4021204dbd89505751993d399d",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2558.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df42fe2cf6914ba981c85fccf7ae30a3",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kQh7M9FWclnE",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425698604,
     "user_tz": -120,
     "elapsed": 3286315,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "import pandas as pd\n",
    "predictionLabels = [dictLabelsReverse[t] for t in predictions]\n",
    "dfResults = pd.DataFrame(predictionLabels, columns=[\"prediction\"])\n",
    "dfResults[\"gold\"] = dfTest[[\"account.type\"]]\n",
    "file_name = resultsDir+\"/bert_finetuning.csv\"\n",
    "dfResults.to_csv(file_name, sep='\\t', encoding='utf-8')"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cGwuVWcsaZse",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425698605,
     "user_tz": -120,
     "elapsed": 3286310,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "dfTest[\"label_bert\"] = [dictLabelsReverse[t] for t in predictions]"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wbdb87Ix1U3H",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425698605,
     "user_tz": -120,
     "elapsed": 3286304,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "ed7faef0-7f21-4329-94cf-7729941b74f0"
   },
   "source": [
    "dfResults.head()"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bot</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction   gold\n",
       "0      human  human\n",
       "1      human  human\n",
       "2        bot  human\n",
       "3        bot    bot\n",
       "4      human  human"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 34
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5z4JICTNSTbX",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425698606,
     "user_tz": -120,
     "elapsed": 3286300,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    "def plotErrorRatio(X_test_all, prediction_column, min_sample_num=30):\n",
    "  X_verify = X_test_all[[\"screen_name\", \"text\", \"account.type\", prediction_column]]\n",
    "  X_count_accounts = X_test_all[[\"screen_name\", \"account.type\"]].groupby(\"screen_name\").count()\n",
    "  X_verify = X_verify[X_verify[\"account.type\"] != X_verify[prediction_column]]\n",
    "  X_verify = X_verify.groupby(\"screen_name\").count()[\"text\"].to_frame()\n",
    "  X_verify[\"total\"] = X_count_accounts[\"account.type\"]\n",
    "  X_verify.columns = [\"errors\", \"num_samples\"]\n",
    "  X_verify[\"error_ratio\"] = X_verify[\"errors\"] / X_verify[\"num_samples\"]\n",
    "  X_verify[X_verify[\"num_samples\"] >= min_sample_num][\"error_ratio\"].plot.bar(figsize=(15,5))\n",
    "  return X_verify"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HkD_xLJ9zCRR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425699027,
     "user_tz": -120,
     "elapsed": 3286715,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "f74e4d90-f71e-4fad-f73b-68321244955b"
   },
   "source": [
    "plotErrorRatio(dfTest, \"label_bert\")"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>errors</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>error_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DeepDrumpf</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenePark</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenePark_GPT2</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gpt2Wint</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thorin</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilityLimb</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VBoterin</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahadsheriff</th>\n",
       "      <td>14</td>\n",
       "      <td>95</td>\n",
       "      <td>0.147368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahadsheriffbot</th>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awhalefact</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>botustrump</th>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0.171429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calebgamman</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calebgamman2</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dril</th>\n",
       "      <td>56</td>\n",
       "      <td>180</td>\n",
       "      <td>0.311111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dril_gpt2</th>\n",
       "      <td>53</td>\n",
       "      <td>179</td>\n",
       "      <td>0.296089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elonmusk</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2_trump</th>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imranye</th>\n",
       "      <td>13</td>\n",
       "      <td>129</td>\n",
       "      <td>0.100775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imranyebot</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>0.054264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaden</th>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevinhooke</th>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "      <td>0.016598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narendramodi</th>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ninjasexparty</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsp_gpt2</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realDonaldTrump</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "      <td>0.077519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarcastic_trump</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theJadenTrudeau</th>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>0.029126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whalefakes</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zawarbot</th>\n",
       "      <td>9</td>\n",
       "      <td>152</td>\n",
       "      <td>0.059211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zawvrk</th>\n",
       "      <td>22</td>\n",
       "      <td>152</td>\n",
       "      <td>0.144737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 errors  num_samples  error_ratio\n",
       "screen_name                                      \n",
       "DeepDrumpf            1           29     0.034483\n",
       "GenePark              1           22     0.045455\n",
       "GenePark_GPT2         6           22     0.272727\n",
       "Gpt2Wint              1            2     0.500000\n",
       "Thorin                3           10     0.300000\n",
       "UtilityLimb           2            4     0.500000\n",
       "VBoterin              1           13     0.076923\n",
       "ahadsheriff          14           95     0.147368\n",
       "ahadsheriffbot        5           95     0.052632\n",
       "awhalefact            2           35     0.057143\n",
       "botustrump            6           35     0.171429\n",
       "calebgamman           7           13     0.538462\n",
       "calebgamman2          5           13     0.384615\n",
       "dril                 56          180     0.311111\n",
       "dril_gpt2            53          179     0.296089\n",
       "elonmusk              2            6     0.333333\n",
       "gpt2_trump           11           55     0.200000\n",
       "imranye              13          129     0.100775\n",
       "imranyebot            7          129     0.054264\n",
       "jaden                 4           51     0.078431\n",
       "kevinhooke            4          241     0.016598\n",
       "narendramodi          1          124     0.008065\n",
       "ninjasexparty         9           23     0.391304\n",
       "nsp_gpt2              4           23     0.173913\n",
       "realDonaldTrump      10          129     0.077519\n",
       "sarcastic_trump       1            5     0.200000\n",
       "theJadenTrudeau       3          103     0.029126\n",
       "whalefakes            2           35     0.057143\n",
       "zawarbot              9          152     0.059211\n",
       "zawvrk               22          152     0.144737"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 36
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MFxq59MLEtkh",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595425699392,
     "user_tz": -120,
     "elapsed": 3287074,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    }
   },
   "source": [
    ""
   ],
   "execution_count": 36,
   "outputs": []
  }
 ]
}